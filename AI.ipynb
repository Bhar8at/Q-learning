{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from game import env\n",
    "import random\n",
    "from tqdm import tqdm  # modified import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initializing the structure\n",
    "def make_matrix(x):\n",
    "    return [[\" 0 \" for i in range(x)] for i in range(x)]\n",
    "\n",
    "\n",
    "# UI related functions\n",
    "def display(matrix):\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            print(matrix[i][j], end=\" \")\n",
    "        print()\n",
    "\n",
    "def space():\n",
    "    print(\"\\n\"*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprite logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "class sprite():\n",
    "    \n",
    "    def __init__(self, char, matrix, type):\n",
    "        if type == \"checkpoint\":\n",
    "            self.x = len(matrix)-1\n",
    "            self.y = len(matrix)-1\n",
    "        else:\n",
    "            self.x = randint(0,len(matrix)-1)\n",
    "            self.y = randint(0,len(matrix)-2)\n",
    "        self.char = char\n",
    "        self.background = matrix\n",
    "\n",
    "    def move_up(self):\n",
    "        if self.y - 1 in range(len(self.background)):\n",
    "            self.y -=1\n",
    "\n",
    "    def move_down(self):\n",
    "        if self.y + 1 in range(len(self.background)):\n",
    "            self.y +=1\n",
    "\n",
    "    def move_right(self):\n",
    "        if self.x + 1 in range(len(self.background)):\n",
    "            self.x +=1\n",
    "\n",
    "    def move_left(self):\n",
    "        if self.x - 1 in range(len(self.background)):\n",
    "            self.x -=1\n",
    "    \n",
    "    def set_position(self):\n",
    "        self.background[self.y][self.x] = self.char\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class env():\n",
    "    def __init__(self):\n",
    "        self.matrix = make_matrix(5)\n",
    "        self.character = sprite(\" ^ \", self.matrix, \"\")\n",
    "        self.checkpoint = sprite(\" X \", self.matrix, \"checkpoint\")\n",
    "        self.character.set_position()\n",
    "        self.checkpoint.set_position()\n",
    "        self.distance = (self.character.x - self.checkpoint.x)**2 + (self.character.y - self.checkpoint.y)**2\n",
    "        \n",
    "        self.score = 0\n",
    "        self.steps = 0\n",
    "\n",
    "    def get_state(self):\n",
    "        self.state =   self.character.x + self.character.y * len(self.matrix)\n",
    "        return self.state\n",
    "    \n",
    "    def reset(self):\n",
    "        self.steps = 0\n",
    "        self.character.set_position()\n",
    "        self.checkpoint.set_position()\n",
    "        return self.get_state()\n",
    "\n",
    "    def check_coincide(self):\n",
    "        return self.character.x == self.checkpoint.x and self.character.y == self.checkpoint.y\n",
    "    \n",
    "    def update_matrix(self):\n",
    "        for i in range(len(self.matrix)):\n",
    "            for j in range(len(self.matrix)):\n",
    "                if self.matrix[i][j] == \" ^ \":\n",
    "                    self.matrix[i][j] = \" 0 \"\n",
    "        self.matrix[self.character.y][self.character.x] = \" ^ \"\n",
    "    def check_coincide(self):\n",
    "        return self.character.x == self.checkpoint.x and self.character.y == self.checkpoint.y\n",
    "    \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.character.move_up()\n",
    "        elif action == 1:\n",
    "            self.character.move_down()\n",
    "        elif action == 2:\n",
    "            self.character.move_left()\n",
    "        elif action == 3:\n",
    "            self.character.move_right()\n",
    "\n",
    "        new_distance = (self.character.x - self.checkpoint.x)**2 + (self.character.y - self.checkpoint.y)**2\n",
    "        if self.check_coincide():\n",
    "            reward = 10\n",
    "            done = True\n",
    "        elif new_distance < self.distance:\n",
    "            reward = 1\n",
    "            done = False\n",
    "        else:\n",
    "            reward = -1\n",
    "            done = False\n",
    "\n",
    "        self.state = self.get_state()\n",
    "        self.update_matrix()\n",
    "        return self.matrix, reward, done\n",
    "    \n",
    "    def render(self):\n",
    "        display(self.matrix)\n",
    "        self.steps += 1\n",
    "        if self.steps > 10:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        return done\n",
    "    \n",
    "    def possible_states(self):\n",
    "        return len(self.matrix)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_training_episodes = 10000  # Total training episodes\n",
    "learning_rate = 0.7          # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "\n",
    "# Environment parameters\n",
    "env_id = \"FrozenLake-v1\"     # Name of the environment\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "eval_seed = []               # The evaluation seed of the environment\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.05            # Minimum exploration probability\n",
    "decay_rate = 0.0005            # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = env()\n",
    "state_space = len(game.matrix)**2 # Make this the number of states in your environment\n",
    "action_space = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_q_table(state_space, action_space):\n",
    "  Qtable = np.zeros((state_space,action_space))\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_policy(Qtable, state):\n",
    "  # Exploitation: take the action with the highest state, action value\n",
    "  action = np.argmax(Qtable[state][:])\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
    "  # Randomly generate a number between 0 and 1\n",
    "  random_num = random.uniform(0,1)\n",
    "  # if random_num > greater than epsilon --> exploitation\n",
    "  if random_num > epsilon:\n",
    "    # Take the action with the highest value given a state\n",
    "    # np.argmax can be useful here\n",
    "    action = np.argmax(Qtable[state][:])\n",
    "  # else --> exploration\n",
    "  else:\n",
    "    action = random.randint(0,3)# Take a random action\n",
    "\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
    "  for episode in tqdm(range(n_training_episodes)):\n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "    # Reset the environment\n",
    "    state = env.reset()\n",
    "    terminated = False\n",
    "\n",
    "    # repeat\n",
    "    for step in range(max_steps):\n",
    "      # Choose the action At using epsilon greedy policy\n",
    "      action = epsilon_greedy_policy(Qtable, state, epsilon)\n",
    "\n",
    "      # Take action At and observe Rt+1 and St+1\n",
    "      # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "      matrix, reward, terminated = env.step(action)\n",
    "      new_state = env.get_state()\n",
    "      env.matrix = matrix\n",
    "      env.render()\n",
    "      # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "      Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.argmax(Qtable[new_state] - Qtable[state]))\n",
    "\n",
    "      # If terminated or truncated finish the episode\n",
    "      if terminated:\n",
    "        break\n",
    "\n",
    "      # Our next state is the new state\n",
    "      state = new_state\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtable = initialize_q_table(state_space, action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtable = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, game, max_steps, Qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0   0   0   0   0  \n",
      " 0   0   0   0   0  \n",
      " 0   0   0   0   0  \n",
      " 0   0   0   0   0  \n",
      " 0   0   0   0   X  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = game.reset()\n",
    "terminated = False\n",
    "\n",
    "game.render()\n",
    "# for step in range(max_steps):\n",
    "#     game.render()\n",
    "#     time.sleep(0.5)\n",
    "#     # Choose the action At using epsilon greedy policy\n",
    "#     action = greedy_policy(Qtable, state)\n",
    "    \n",
    "#     # Take action At and observe Rt+1 and St+1\n",
    "#     # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "#     matrix, reward, terminated = game.step(action)\n",
    "#     new_state = game.get_state()\n",
    "#     game.matrix = matrix\n",
    "    \n",
    "#     # If terminated finish the game\n",
    "#     if terminated:\n",
    "#         break\n",
    "    \n",
    "#     # Our next state is the new state\n",
    "#     state = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
